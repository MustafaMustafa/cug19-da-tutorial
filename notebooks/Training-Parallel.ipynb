{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-node training example\n",
    "\n",
    "In this script we are going to demonstrate how to perform a multi-node training using keras and horovod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Up Ipyparallel Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup ipyparallel\n",
    "import ipyparallel as ipp\n",
    "\n",
    "#load slurm extensions\n",
    "%load_ext slurm_magic\n",
    "\n",
    "#get username\n",
    "username = !whoami\n",
    "username = username[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose desired concurrency\n",
    "n_ranks = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Submitted batch job 20629394\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#submit cluster setup script\n",
    "%sbatch -N $n_ranks ../scripts/start-cluster.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/common/software/tensorflow/intel-tensorflow/1.13.0-py36-dev/lib/python3.6/site-packages/slurm_magic.py:22: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  error_bad_lines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOBID</th>\n",
       "      <th>PARTITION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>USER</th>\n",
       "      <th>ST</th>\n",
       "      <th>TIME</th>\n",
       "      <th>NODES</th>\n",
       "      <th>NODELIST(REASON)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20629394</td>\n",
       "      <td>regular</td>\n",
       "      <td>ipyparal</td>\n",
       "      <td>tkurth</td>\n",
       "      <td>PD</td>\n",
       "      <td>0:00</td>\n",
       "      <td>1</td>\n",
       "      <td>(None)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20629351</td>\n",
       "      <td>interacti</td>\n",
       "      <td>sh</td>\n",
       "      <td>tkurth</td>\n",
       "      <td>R</td>\n",
       "      <td>0:09</td>\n",
       "      <td>16</td>\n",
       "      <td>nid0[2304-2319]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      JOBID  PARTITION      NAME    USER  ST  TIME  NODES NODELIST(REASON)\n",
       "0  20629394    regular  ipyparal  tkurth  PD  0:00      1           (None)\n",
       "1  20629351  interacti        sh  tkurth   R  0:09     16  nid0[2304-2319]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if job is ready\n",
    "squeueout = %squeue -u $username\n",
    "squeueout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for running jobs and extract their id's\n",
    "job_id = squeueout.loc[ (squeueout[\"ST\"] == \"R\") & (squeueout[\"NAME\"].str.startswith(\"ipy\")), \"JOBID\"]\n",
    "\n",
    "if not job_id.empty:\n",
    "    cluster_id = \"cori_\" + str(job_id.values[0])\n",
    "\n",
    "    print(\"Creating cluster {}\".format(cluster_id))\n",
    "    \n",
    "    #now create the cluster\n",
    "    clust = ipp.Client(timeout=60, cluster_id=cluster_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Pick up the local code\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Externals\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Locals\n",
    "from data import get_datasets\n",
    "from models import get_model\n",
    "from utils.device import configure_session\n",
    "from utils.optimizers import get_optimizer\n",
    "from utils.callbacks import TimingCallback\n",
    "\n",
    "#some training specific stuff\n",
    "from train_horovod import init_workers, get_basic_callbacks\n",
    "\n",
    "#import horovod\n",
    "import horovod.keras as hvd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We will be doing image classification on CIFAR10:\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "We will be training a simple CNN model to classify small images into 10 classes.\n",
    "\n",
    "Let's start by looking at some example images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --targets 0\n",
    "\n",
    "#load the dataset and plot, only on rank 0\n",
    "x, y = cifar10.load_data()[0]\n",
    "\n",
    "nrows = 8\n",
    "ncols = 8\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 12), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.imshow(x[i])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Here is where we will specify all of our configuration of the processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# MPI stuff\n",
    "my_rank = None\n",
    "num_ranks = None\n",
    "cb = None\n",
    "\n",
    "# init workers (do not init twice)\n",
    "if not my_rank or not num_ranks:\n",
    "    my_rank, num_ranks = init_workers(distributed = True)\n",
    "\n",
    "print(my_rank, num_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# On-Node config\n",
    "gpu = None\n",
    "intra_threads = 33 # CPU performance knob\n",
    "inter_threads = 2 # CPU performance knob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# configure session\n",
    "configure_session(gpu=gpu, intra_threads=intra_threads, inter_threads=inter_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model and load the data\n",
    "\n",
    "Now we use our local get_model code to build our CNN model according to our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Model config\n",
    "model_name = 'cnn'\n",
    "input_shape = [32, 32, 3]\n",
    "n_classes = 10\n",
    "dropout = 0.1\n",
    "\n",
    "# Optimizer config\n",
    "optimizer_name = 'Adam'\n",
    "lr = 0.001\n",
    "\n",
    "# Training config\n",
    "batch_size = 32\n",
    "n_epochs = 50\n",
    "loss_name = 'categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "# Additional tweaks\n",
    "warmup_epochs = 0\n",
    "lr_schedule = []\n",
    "\n",
    "# Load the data\n",
    "train_gen, valid_gen = get_datasets(name='cifar10', batch_size=batch_size)\n",
    "train_steps = max([len(train_gen) // num_ranks, 1])\n",
    "valid_steps = max([len(valid_gen) // num_ranks, 1])\n",
    "\n",
    "# Build the model and optimizer\n",
    "model = get_model(name=model_name, input_shape=input_shape, n_classes=n_classes, dropout=dropout)\n",
    "opt = get_optimizer(name=optimizer_name, lr=lr, n_ranks=num_ranks)\n",
    "model.compile(loss=loss_name, optimizer=opt, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "\n",
    "#print model summary only on rank 0\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Callbacks\n",
    "\n",
    "These are relevant for initial variable broadcasting, LR warmup, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "#list of callbacks\n",
    "cb = get_basic_callbacks(distributed = True)\n",
    "\n",
    "#warmups:\n",
    "if warmup_epochs > 0:\n",
    "    cb.append(hvd.callbacks.LearningRateWarmupCallback(warmup_epochs=warmup_epochs))\n",
    "\n",
    "#lr_schedule\n",
    "for lr_schedule in lr_schedule:\n",
    "    cb.append(hvd.callbacks.LearningRateScheduleCallback(**lr_schedule))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We use the fit_generator method to train our CNN model on our data generators.\n",
    "\n",
    "Watch the progess as our model eats through the training data and regularly evaluates on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# Train the model\n",
    "train_history = model.fit_generator(train_gen,\n",
    "                                    epochs = n_epochs,\n",
    "                                    steps_per_epoch =train_steps,\n",
    "                                    validation_data = valid_gen,\n",
    "                                    validation_steps = valid_steps,\n",
    "                                    verbose = 1 if my_rank==0 else 0,\n",
    "                                    callbacks = cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training history\n",
    "\n",
    "Training has now completed. We can use the returned history object to make plots of the training and validation set losses and accuracies during training. This is very valuable for identifying issues like under/over fitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px --target 0\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "# Plot the loss\n",
    "ax0.plot(train_history.epoch, train_history.history['loss'], label='train')\n",
    "ax0.plot(train_history.epoch, train_history.history['val_loss'], label='validation')\n",
    "ax0.set_xlabel('Epoch')\n",
    "ax0.set_ylabel('Loss')\n",
    "ax0.legend(loc=0)\n",
    "\n",
    "# Plot the accuracy\n",
    "ax1.plot(train_history.epoch, train_history.history['acc'], label='train')\n",
    "ax1.plot(train_history.epoch, train_history.history['val_acc'], label='validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(bottom=0, top=1)\n",
    "ax1.legend(loc=0)\n",
    "\n",
    "#prettify layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to try next?\n",
    "\n",
    "Now that you've gotten this far, familiarize yourself with what you can change in the configuration and the effect it has on model performance.\n",
    "\n",
    "For example:\n",
    "- What happens if you increase or decrease the learning rate by a factor of 10?\n",
    "- What happens if you greatly increase or decrease the size of the model in number and size of layers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-1.13.0-py36-dev",
   "language": "python",
   "name": "tensorflow-1.13.0-py36-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
